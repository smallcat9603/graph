{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neo4j desktop (5.3.0, m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "host = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password= \"j4oenj4oen\"\n",
    "\n",
    "gds = GraphDataScience(host, auth=(user, password))\n",
    "print(gds.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Noun-Article (Star) Graph　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/data.json\", \"r\") as file:\n",
    "#     data = json.load(file)\n",
    "# for key in data:\n",
    "#     for element0 in data[key]:\n",
    "#         for element1 in data[key][element0]:\n",
    "#             node = element0 + \"-\" + element1\n",
    "#             if \"tfidf\" not in data[key][element0][element1]:\n",
    "#                 query = \"\"\"\n",
    "#                 MERGE (n:Noun {name:$key})\n",
    "#                 MERGE (a:Article {name:$node, lines:$lines})\n",
    "#                 MERGE (n)-[l:APPEAR_IN]-(a)\n",
    "#                 \"\"\"\n",
    "#                 params = {'key': key, 'node': node, 'lines': data[key][element0][element1][\"lines\"]}\n",
    "#                 gds.run_cypher(query, params)\n",
    "#             else:\n",
    "#                 query = \"\"\"\n",
    "#                 MERGE (n:Noun {name:$key})\n",
    "#                 MERGE (a:Article {name:$node, lines:$lines, tfidf:$tfidf})\n",
    "#                 MERGE (n)-[l:APPEAR_IN]-(a)\n",
    "#                 \"\"\"\n",
    "#                 params = {'key': key, 'node': node, 'lines': data[key][element0][element1][\"lines\"], 'tfidf': data[key][element0][element1][\"tfidf\"]}\n",
    "#                 gds.run_cypher(query, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Noun-[Verb]-Noun Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"\n",
    "# LOAD CSV WITH HEADERS FROM 'file:///noun-verb.csv' AS row\n",
    "# MERGE (s:Noun {name:row.source})\n",
    "# MERGE (t:Noun {name:row.target})\n",
    "# MERGE (s)-[i:INTERACTS {name:row.edge}]->(t)\n",
    "# \"\"\"\n",
    "# gds.run_cypher(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Article-[Noun]-Article Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'body': [], 'time': [], 'title': [{'text': 'D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               value\n",
       "0  {'body': [], 'time': [], 'title': [{'text': 'D..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = \"\"\"\n",
    "# LOAD CSV WITH HEADERS FROM 'https://raw.githubusercontent.com/smallcat9603/graph/main/dnp/kg/data/articles.csv' AS row\n",
    "# RETURN row\n",
    "# LIMIT 10\n",
    "# \"\"\"\n",
    "# gds.run_cypher(query)\n",
    "\n",
    "query = \"\"\"\n",
    "MERGE (a:Article {url: \"https://www.dnp.co.jp/news/detail/20169924_1587.html\"})\n",
    "WITH a\n",
    "CALL apoc.load.html(a.url, {\n",
    " body: 'body div.spec__body p',\n",
    " title: 'h1',\n",
    " time: 'time'\n",
    "})\n",
    "YIELD value\n",
    "UNWIND value.body AS item\n",
    "WITH a,\n",
    "     apoc.text.join(collect(item.text), '') AS body,\n",
    "     value.title[0].text AS title,\n",
    "     value.time[0].attributes.datetime AS date\n",
    "SET a.body = body , a.title = title, a.datetime = datetime(date)\n",
    "RETURN a.body\n",
    "\"\"\"\n",
    "gds.run_cypher(query)\n",
    "\n",
    "# query = \"\"\"\n",
    "# MERGE (a:Article {name: \"B-1.txt\", body: \"We use RethinkDB at work across different projects. It isn’t used for any sort of big-data applications, but rather as a NoSQL database, which spices things up with real-time updates, and relational tables support.RethinkDB features an officially supported Node.js driver, as well as a community-maintained driver as well called rethinkdbdash which is promises-based, and provides connection pooling. There is also a database migration tool called rethinkdb-migrate that aids in managing database changes such as schema changes, database seeding, tear up and tear down capabilities.We’re going to use the official RethinkDB docker image from the docker hub and make use of docker-compose.yml to spin it up (later on you can add additional services to this setup).A fair example for docker-compose.yml:The compose file mounts a local tls directory as a mapped volume inside the container. The tls/ directory will contain our cert files, and the compose file is reflecting this.To setup a secure connection we need to facilitate it using certificates so an initial technical step:Important notes:Update the compose file to include a command configuration that starts the RethinkDB process with all the required SSL configurationImportant notes:You’ll notice there isn’t any cluster related configuration but you can add them as well if you need to so they can join the SSL connection: — cluster-tls — cluster-tls-key /tls/key.pem — cluster-tls-cert /tls/cert.pem — cluster-tls-ca /tls/ca.pemThe RethinkDB drivers support an ssl optional object which either sets the certificate using the ca property, or sets the rejectUnauthorized property to accept or reject self-signed certificates when connecting. A snippet for the ssl configuration to pass to the driver:Now that the connection is secured, it only makes sense to connect using a user/password which are not the default.To set it up, update the compose file to also include the — initial-password argument so you can set the default admin user’s password. For example:Of course you need to append this argument to the rest of the command line options in the above compose file.Now, update the Node.js driver settings to use a user and password to connect:Congratulations! You’re now eligible to “Ready for Production stickers.Don’t worry, I already mailed them to your address.\"})\n",
    "# \"\"\"\n",
    "# gds.run_cypher(query)\n",
    "\n",
    "# query = \"\"\"\n",
    "# MATCH (a:Article {name: \"B-1.txt\"})\n",
    "# CALL apoc.nlp.gcp.entities.stream(a, {\n",
    "#  nodeProperty: 'body',\n",
    "#  key: 'AIzaSyAPQNUpCCFrsJhX2A-CgvOG4fDWlxuA8ec'\n",
    "# })\n",
    "# YIELD node, value\n",
    "# WITH node, value\n",
    "# UNWIND value.entities AS entity\n",
    "# RETURN entity\n",
    "# LIMIT 5;\n",
    "# \"\"\"\n",
    "# gds.run_cypher(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (postprocessing) free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "MATCH (n) DETACH DELETE n\n",
    "\"\"\"\n",
    "gds.run_cypher(query)\n",
    "gds.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
